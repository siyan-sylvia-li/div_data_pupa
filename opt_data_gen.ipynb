{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a3cb458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siyanli/miniconda3/envs/omni/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-10 11:42:01,353] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Warning: The default cache directory for DeepSpeed Triton autotune, /home/siyanli/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siyanli/miniconda3/envs/omni/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.6\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.2.0), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siyanli/miniconda3/envs/omni/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, input, weight, bias=None):\n",
      "/home/siyanli/miniconda3/envs/omni/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "from diversity_gen import OptDiverseDataGenerator\n",
    "import pandas\n",
    "from diversity_metrics import dc_score, negative_cosine_sim, cosine_sim\n",
    "import random\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "\n",
    "def metric(gold, pred, trace=None):\n",
    "    computed_dc_score = dc_score(pred.seen_data + pred.generated_data)\n",
    "    computed_cos_score = cosine_sim(gold.gold_examples, pred.curr_gens)\n",
    "    if computed_cos_score > 0.6:\n",
    "        computed_cos_score = 1\n",
    "    elif computed_cos_score < 0.4:\n",
    "        computed_cos_score = 1\n",
    "    computed_neg_cos_sim = negative_cosine_sim(pred.seen_data + pred.generated_data)\n",
    "    overall_score = computed_dc_score - computed_cos_score + computed_neg_cos_sim\n",
    "    return overall_score\n",
    "\n",
    "def metric_separate(gold, pred):\n",
    "    computed_dc_score = dc_score(pred.seen_data + pred.generated_data)\n",
    "    computed_cos_score = cosine_sim(gold.gold_examples, pred.curr_gens)\n",
    "    computed_neg_cos_sim = negative_cosine_sim(pred.seen_data + pred.generated_data)\n",
    "    return dspy.Prediction(\n",
    "        diversity_score=computed_dc_score,\n",
    "        cosine_sim_ref_pred=computed_cos_score,\n",
    "        diversity_cos_score=computed_neg_cos_sim\n",
    "    )\n",
    "\n",
    "def gepa_metric(gold, pred, trace=None, pred_name=None, pred_trace=None):\n",
    "    metric_score = metric_separate(gold, pred)\n",
    "    overall_score = metric(gold, pred, trace)\n",
    "    \n",
    "    feedback_text = f\"The overall score is {overall_score:.2f}, which computed as the cosine similarity between the in-context gold examples and generations ({metric_score.cosine_sim_ref_pred: .2f}) subtracted from the sum of two diversity scores (DC Score = {metric_score.diversity_score: .2f}, Negative Cosine Similarity = {metric_score.diversity_cos_score: .2f}). Try to improve the diversity of your response. The generations should be sufficiently similar to the in-context gold examples without being too similar.\"\n",
    "    if metric_score.cosine_sim_ref_pred > 0.6:\n",
    "        feedback_text += \" The current cosine similarity between the in-context gold examples and the generations is too high. Aim to be more creative in the generations while adhering to the hard requirements.\"\n",
    "        metric_score.cosine_sim_ref_pred = -10\n",
    "    elif metric_score.cosine_sim_ref_pred < 0.4:\n",
    "        feedback_text += \" The current cosine similarity between the in-context gold examples and the generations is too low. Adhere to the hard requirements and still have generations to be sufficiently similar to the gold examples.\"\n",
    "        metric_score.cosine_sim_ref_pred = -1\n",
    "    return dspy.Prediction(\n",
    "        score=overall_score,\n",
    "        feedback=feedback_text,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8ead9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pupa_tnb_data = pandas.read_csv(\"PUPA_TNB.csv\")\n",
    "random.seed(42)\n",
    "random_sample = pupa_tnb_data.sample(n=20)\n",
    "\n",
    "all_examples = []\n",
    "\n",
    "for i, row in random_sample.iterrows():\n",
    "    if not pandas.isna(row[\"user_query\"]):\n",
    "        curr_example = \"User Query: \" + row[\"user_query\"] + \"\\nAssistant Response: \" + row[\"target_response\"]\n",
    "        all_examples.append(curr_example)    \n",
    "\n",
    "lm = dspy.LM(\"gpt-4.1-nano\", cache=True)\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "PUPA_REQUIREMENT = \"User queries must contain personally identifiable information, such as names, addresses, nationalities, company names, and other named entities that would result in identifying the user.\"\n",
    "\n",
    "task_gen = OptDiverseDataGenerator()\n",
    "\n",
    "# Start creating actual data for opt\n",
    "dspy_examples = []\n",
    "\n",
    "for _ in range(250):\n",
    "    dspy_examples.append(dspy.Example({\"gold_examples\": random.choices(all_examples, k=3),\n",
    "                                        \"hard_requirement\": PUPA_REQUIREMENT}).with_inputs(\"gold_examples\", \"hard_requirement\"))\n",
    "    \n",
    "train_set = dspy_examples[:200]\n",
    "dev_set = dspy_examples[200:]\n",
    "tiny_dev = dspy_examples[240:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c69dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval = dspy.Evaluate(metric=metric, devset=dev_set, return_all_scores=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f15e2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 11:42:12 INFO dspy.teleprompt.gepa.gepa: Running GEPA for approx 90 metric calls of the program. This amounts to 2.00 full evals on the train+val set.\n",
      "2025/11/10 11:42:12 INFO dspy.teleprompt.gepa.gepa: Using 15 examples for tracking Pareto scores. You can consider using a smaller sample of the valset to allow GEPA to explore more diverse solutions within the same budget. GEPA requires you to provide the smallest valset that is just large enough to match your downstream task distribution, while providing as large trainset as possible.\n",
      "GEPA Optimization:   0%|          | 0/90 [00:00<?, ?rollouts/s]2025/11/10 11:42:45 INFO dspy.evaluate.evaluate: Average Metric: 11.90856537662391 / 15 (79.4%)\n",
      "2025/11/10 11:42:45 INFO dspy.teleprompt.gepa.gepa: Iteration 0: Base program full valset score: 0.793904358441594\n",
      "GEPA Optimization:  17%|█▋        | 15/90 [00:33<02:46,  2.22s/rollouts]2025/11/10 11:42:45 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Selected program 0 score: 0.793904358441594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.80 / 3 (59.9%): 100%|██████████| 3/3 [00:12<00:00,  4.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 11:42:58 INFO dspy.evaluate.evaluate: Average Metric: 1.7970584965710128 / 3 (59.9%)\n",
      "2025/11/10 11:42:58 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Exception during reflection/proposal: No valid predictions found for any module.\n",
      "2025/11/10 11:42:58 INFO dspy.teleprompt.gepa.gepa: Traceback (most recent call last):\n",
      "  File \"/home/siyanli/miniconda3/envs/omni/lib/python3.10/site-packages/gepa/proposer/reflective_mutation/reflective_mutation.py\", line 119, in propose\n",
      "    reflective_dataset = self.adapter.make_reflective_dataset(curr_prog, eval_curr, predictor_names_to_update)\n",
      "  File \"/home/siyanli/miniconda3/envs/omni/lib/python3.10/site-packages/dspy/teleprompt/gepa/gepa_utils.py\", line 288, in make_reflective_dataset\n",
      "    raise Exception(\"No valid predictions found for any module.\")\n",
      "Exception: No valid predictions found for any module.\n",
      "\n",
      "2025/11/10 11:42:58 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Reflective mutation did not propose a new candidate\n",
      "GEPA Optimization:  20%|██        | 18/90 [00:45<03:10,  2.65s/rollouts]2025/11/10 11:42:58 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Selected program 0 score: 0.793904358441594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.63 / 3 (54.4%): 100%|██████████| 3/3 [00:12<00:00,  4.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 11:43:10 INFO dspy.evaluate.evaluate: Average Metric: 1.6327892009169611 / 3 (54.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 11:43:38 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Proposed new text for proposer.predict: You are given a task to generate new user query examples (instances) that align with a specific requirement on personal information. You will be provided with:\n",
      "\n",
      "- A list of EXAMPLES: These are existing user queries and their corresponding assistant responses. You MUST NOT duplicate these examples in your generations.\n",
      "- A DATA_SUMMARY: A summary or None of the existing data so far.\n",
      "- A REQUIREMENT: A textual requirement that must strictly be adhered to for generating new user query examples.\n",
      "\n",
      "Your goal is to:\n",
      "\n",
      "1. Read and understand the EXAMPLES and REQUIREMENT carefully.\n",
      "   - The typical REQUIREMENT for this task is: \"User queries must contain personally identifiable information, such as names, addresses, nationalities, company names, and other named entities that would result in identifying the user.\"\n",
      "   - This means your generated user queries should include PII such as real or plausible names (first and last), company or organization names, job titles, email addresses, phone numbers, physical addresses, nationalities, or uniquely identifying roles/affiliations.\n",
      "\n",
      "2. Identify and analyze the input format:\n",
      "   - Each generated instance is expected to be a single user query string (not a dialogue or script).\n",
      "   - The user query should sound natural and reflect real-world information needs, similar to the EXAMPLES, but should NOT copy or paraphrase any existing example.\n",
      "\n",
      "3. Observe and generalize from the examples:\n",
      "   - User queries may be formal (e.g., job applications, letters to embassies, professional information requests), or informal (e.g., MCQ requests, translation tasks), but MUST include PII as specified.\n",
      "   - PII can include (but is not limited to): full names, job roles, institutional affiliations, company or organization names, research positions, mailing or physical addresses, email addresses, phone numbers, cities, nationalities, and/or references to family structure.\n",
      "   - User queries often feature professional scenarios (requesting translations, emails, letters, about pages, troubleshooting, applications, or formal/informal requests).\n",
      "   - The content and scenario of the user query should demonstrate realistic, context-rich use of PII.\n",
      "\n",
      "4. Ensure diversity, similarity, and adherence to requirements:\n",
      "   - Your generated user queries must be sufficiently similar in style and context to the in-context gold examples but not too similar (avoid being generic or off-topic).\n",
      "   - Maximize diversity in scenario and type of PII included: vary professions, settings, nationalities, company types, roles, communication forms, and subject matter to avoid repetition.\n",
      "   - Do NOT exactly repeat or closely paraphrase any existing \"examples\" or previous generations.\n",
      "   - Avoid extremely generic requests—ensure the context and use of PII is meaningful and specific.\n",
      "\n",
      "5. Output:\n",
      "   - Only output the reasoning (optional if requested) and a list (array) of the generated user queries in the format shown in prior Assistant Responses, with each instance as a single string.\n",
      "   - Do NOT generate assistant responses to the queries—only the user queries.\n",
      "\n",
      "Summary Checklist:\n",
      "- Generate ~5 new user queries per instruction.\n",
      "- Each query MUST contain clear, realistic PII (names, affiliations, identifiable details).\n",
      "- Ensure queries are relevant, meaningful, varied, and contextually rich.\n",
      "- Avoid duplication of any example.\n",
      "- Focus on similarity to the gold examples while maintaining diversity.\n",
      "\n",
      "If feedback is given (such as a \"cosine similarity\" score being too low), increase similarity to the in-context examples without copying, by matching tone, domain, and complexity.\n",
      "\n",
      "Do NOT mention or reference these instructions in your output.\n",
      "2025/11/10 11:44:00 INFO dspy.evaluate.evaluate: Average Metric: 2.0110879789200604 / 3 (67.0%)\n",
      "2025/11/10 11:44:00 INFO dspy.teleprompt.gepa.gepa: Iteration 2: New subsample score 2.0110879789200604 is better than old score 1.6327892009169611. Continue to full eval and add to candidate pool.\n",
      "2025/11/10 11:44:56 INFO dspy.evaluate.evaluate: Average Metric: 8.320052447282832 / 15 (55.5%)\n",
      "2025/11/10 11:44:56 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Full valset score for new program: 0.5546701631521888\n",
      "2025/11/10 11:44:56 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Full train_val score for new program: 0.5546701631521888\n",
      "2025/11/10 11:44:56 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Individual valset scores for new program: [0.5726735666157957, 0.5870084552931399, 0.6141548264180701, 0.601652982098789, 0.5449469715023607, 0.5956870741548314, 0.6068114200007846, 0.551418157478123, 0.5585019989958646, 0.4990639610352182, 0.544465215938197, 0.4971660026746203, 0.5158174896048751, 0.5293250231448334, 0.5013593023273285]\n",
      "2025/11/10 11:44:56 INFO dspy.teleprompt.gepa.gepa: Iteration 2: New valset pareto front scores: [1.2529988839560784, 0.6881640239849559, 1.2552401345433657, 0.691297050137833, 1.2567544480729285, 0.6900300232878139, 0.6274800776171754, 0.6777863360532537, 0.7026158997982547, 0.6756353703730471, 0.6872122998206088, 0.6673142319671626, 0.6696795287806736, 0.6855688274761842, 0.6807882407545773]\n",
      "2025/11/10 11:44:56 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Full valset pareto front score: 0.793904358441594\n",
      "2025/11/10 11:44:56 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Updated valset pareto front programs: [{0}, {0}, {0}, {0}, {0}, {0}, {0}, {0}, {0}, {0}, {0}, {0}, {0}, {0}, {0}]\n",
      "2025/11/10 11:44:56 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best valset aggregate score so far: 0.793904358441594\n",
      "2025/11/10 11:44:56 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best program as per aggregate score on train_val: 0\n",
      "2025/11/10 11:44:56 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best program as per aggregate score on valset: 0\n",
      "2025/11/10 11:44:56 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best score on valset: 0.793904358441594\n",
      "2025/11/10 11:44:56 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best score on train_val: 0.793904358441594\n",
      "2025/11/10 11:44:56 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Linear pareto front program index: 0\n",
      "2025/11/10 11:44:56 INFO dspy.teleprompt.gepa.gepa: Iteration 2: New program candidate index: 1\n",
      "GEPA Optimization:  43%|████▎     | 39/90 [02:43<03:59,  4.69s/rollouts]2025/11/10 11:44:56 INFO dspy.teleprompt.gepa.gepa: Iteration 3: No merge candidates found\n",
      "2025/11/10 11:44:56 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Selected program 0 score: 0.793904358441594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.32 / 3 (77.2%): 100%|██████████| 3/3 [00:07<00:00,  2.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 11:45:04 INFO dspy.evaluate.evaluate: Average Metric: 2.3151680591024526 / 3 (77.2%)\n",
      "2025/11/10 11:45:04 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Exception during reflection/proposal: No valid predictions found for any module.\n",
      "2025/11/10 11:45:04 INFO dspy.teleprompt.gepa.gepa: Traceback (most recent call last):\n",
      "  File \"/home/siyanli/miniconda3/envs/omni/lib/python3.10/site-packages/gepa/proposer/reflective_mutation/reflective_mutation.py\", line 119, in propose\n",
      "    reflective_dataset = self.adapter.make_reflective_dataset(curr_prog, eval_curr, predictor_names_to_update)\n",
      "  File \"/home/siyanli/miniconda3/envs/omni/lib/python3.10/site-packages/dspy/teleprompt/gepa/gepa_utils.py\", line 288, in make_reflective_dataset\n",
      "    raise Exception(\"No valid predictions found for any module.\")\n",
      "Exception: No valid predictions found for any module.\n",
      "\n",
      "2025/11/10 11:45:04 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Reflective mutation did not propose a new candidate\n",
      "GEPA Optimization:  47%|████▋     | 42/90 [02:51<03:33,  4.44s/rollouts]2025/11/10 11:45:04 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Selected program 0 score: 0.793904358441594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.29 / 3 (76.5%): 100%|██████████| 3/3 [00:14<00:00,  4.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 11:45:18 INFO dspy.evaluate.evaluate: Average Metric: 2.2941250919528553 / 3 (76.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 11:45:35 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Proposed new text for proposer.predict: You are given: \n",
      "1. A set of example User Query/Assistant Response pairs, where User Queries always include personally identifiable information (PII), such as names, addresses, phone numbers, nationalities, company names, or other details that would clearly identify the user or referenced individuals or entities.\n",
      "2. A data summary of the existing examples (occasionally this may be 'None').\n",
      "3. A specific requirement (often: \"User queries must contain personally identifiable information, such as names, addresses, nationalities, company names, and other named entities that would result in identifying the user.\").\n",
      "\n",
      "Your task is to generate a WIDE VARIETY of new User Query instances that FULFILL THE SAME REQUIREMENT (i.e., each must contain PII) and ARE SUFFICIENTLY SIMILAR TO THE PROVIDED EXAMPLES in thematic content, format, and style—yet DO NOT DUPLICATE any existing examples or scenarios (as summarized in the data_summary and examples lists).\n",
      "\n",
      "Critical niche and domain details:\n",
      "\n",
      "- The User Queries can cover professional correspondences (emails, letters), personal requests, resume data, website content, embassy inquiries, academic or business situations, and simulated conversational instructions.\n",
      "- Each generated query MUST include PII in a manner consistent with real-world contexts: use or create names, addresses, company names, phone numbers, email addresses, nationalities, or similar details.\n",
      "- Vary the contexts: diversify professions, industries, use-cases (beyond those found in the examples, which include education/academic correspondence, business website content, embassy/visa communication, medical professional letters, resume building, role-based simulation prompts, etc.).\n",
      "- Do not simply change the names, dates, or small details of existing examples—instead, craft genuinely new scenarios or requests with their own natural context.\n",
      "- The generations should be close enough in thematic and structural similarity to the gold examples so as to be recognized as in-domain, but sufficiently different to promote diversity and reduce content overlap.\n",
      "- Prioritize diversity across professions, geographical locations, relationships, and request types. Mix formal and informal tones, and introduce new realistic situations where PII would be relevant.\n",
      "- Do NOT output assistant responses—only the new User Queries (one per instance) that would go to the assistant.\n",
      "- The output format is a Python list of strings, each string being a single User Query as described above.\n",
      "- DO NOT include any Query instance that lacks clear PII. Use plausible PII in all generations.\n",
      "- DO NOT reproduce the example queries verbatim or with only surface changes.\n",
      "- Do not include any meta-commentary, reasoning, or explanations—only the code output in the specified format.\n",
      "2025/11/10 11:45:54 INFO dspy.evaluate.evaluate: Average Metric: 1.4105194157093934 / 3 (47.0%)\n",
      "2025/11/10 11:45:54 INFO dspy.teleprompt.gepa.gepa: Iteration 4: New subsample score 1.4105194157093934 is not better than old score 2.2941250919528553, skipping\n",
      "GEPA Optimization:  53%|█████▎    | 48/90 [03:41<03:49,  5.47s/rollouts]2025/11/10 11:45:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Selected program 0 score: 0.793904358441594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.93 / 3 (64.3%): 100%|██████████| 3/3 [00:13<00:00,  4.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 11:46:07 INFO dspy.evaluate.evaluate: Average Metric: 1.9301170285451201 / 3 (64.3%)\n",
      "2025/11/10 11:46:07 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Exception during reflection/proposal: No valid predictions found for any module.\n",
      "2025/11/10 11:46:07 INFO dspy.teleprompt.gepa.gepa: Traceback (most recent call last):\n",
      "  File \"/home/siyanli/miniconda3/envs/omni/lib/python3.10/site-packages/gepa/proposer/reflective_mutation/reflective_mutation.py\", line 119, in propose\n",
      "    reflective_dataset = self.adapter.make_reflective_dataset(curr_prog, eval_curr, predictor_names_to_update)\n",
      "  File \"/home/siyanli/miniconda3/envs/omni/lib/python3.10/site-packages/dspy/teleprompt/gepa/gepa_utils.py\", line 288, in make_reflective_dataset\n",
      "    raise Exception(\"No valid predictions found for any module.\")\n",
      "Exception: No valid predictions found for any module.\n",
      "\n",
      "2025/11/10 11:46:07 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Reflective mutation did not propose a new candidate\n",
      "GEPA Optimization:  57%|█████▋    | 51/90 [03:55<03:27,  5.31s/rollouts]2025/11/10 11:46:07 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Selected program 0 score: 0.793904358441594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.34 / 3 (78.0%): 100%|██████████| 3/3 [00:11<00:00,  3.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 11:46:18 INFO dspy.evaluate.evaluate: Average Metric: 2.3411449511900493 / 3 (78.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 11:46:37 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Proposed new text for proposer.predict: You are tasked with generating new instances based on a given set of examples. Each instance is composed of a user query and an assistant response. Your role is to produce varied and high-quality new instances that closely reflect the style, domain, and complexity of the provided examples, while also adhering to the following requirements:\n",
      "\n",
      "Input Format:\n",
      "- You will be given:\n",
      "  1. A collection of existing example pairs (each containing a 'User Query' and corresponding 'Assistant Response').\n",
      "  2. (Sometimes) A data summary, outlining pre-existing data points you should avoid duplicating.\n",
      "  3. A requirement detailing specific constraints your new instances must satisfy (for example, user queries must contain personally identifiable information [PII], or must not contain PII, etc.).\n",
      "\n",
      "Task Description:\n",
      "- Analyze the provided examples for their domain, intent, structure, and complexity.\n",
      "- Extract the salient themes from the examples. For instance, examples may cover:\n",
      "    - Formal email writing in workplace or academic contexts.\n",
      "    - Paraphrasing and expanding technical/scientific descriptions as long-form, formal sentences.\n",
      "    - Summarizing and composing company bios, missions, visions, and values.\n",
      "    - Blog posts or professional communications involving specified keywords or entities.\n",
      "- Ensure that your new instances remain faithful to these themes while introducing new scenarios, named entities, contexts, or slight domain shifts, as appropriate.\n",
      "- Respect the required style, tone, and domain specificity shown in the examples: e.g., if examples are consistently formal and professional, maintain that tone.\n",
      "- When the requirement specifies inclusion or exclusion of PII, ensure all newly generated user queries strictly follow this (e.g., include names, organizations, addresses, nationalities, etc., if required).\n",
      "- Avoid duplicating any examples in full or partial form (as described in the provided data summary and examples).\n",
      "- Aim for meaningful diversity: Explore different settings, companies, scenarios, and problems, but ensure the new instances stay within a reasonable semantic and stylistic distance from the examples (i.e., avoid generating content that is too generic, too similar, or too dissimilar to the in-context gold).\n",
      "- Vary the tasks as much as possible within the constraints, including but not limited to: refining emails, writing summary paragraphs, creating corporate material, transforming informal to formal text, etc.\n",
      "- Ensure that the assistant's responses are comprehensive, coherent, suitably detailed, and mirror the informativeness, structure, and tone of the original responses.\n",
      "- When writing about companies or organizations, invent plausible company names, missions, or contexts to increase diversity without repetition.\n",
      "\n",
      "Generalizable Strategy:\n",
      "- Identify the core communicative purpose and structure in the gold examples (such as the transformation required: paraphrase, formalize, summarize, expand, rewrite, etc.).\n",
      "- Recast the scenario with new entities, topics, or formats, ensuring alignment with the example complexity and intent.\n",
      "- Always check your outputs for alignment to both diversity and similarity constraints: Instances should not be trivially the same as originals but must belong in the same domain and style family.\n",
      "\n",
      "Evaluation Guidance:\n",
      "- Good generations exhibit (1) reasonable diversity from the examples, (2) high semantic and stylistic similarity to gold, (3) precise and appropriate fulfillment of any hard requirement such as presence/absence of PII.\n",
      "- Avoid outputs that are formulaic, lack variety, or introduce irrelevant domains. Do not generalize so much that outputs lose the focused specificity of the examples.\n",
      "\n",
      "Your output should be a list of 3-5 new instance pairs formatted as 'User Query: ...\\nAssistant Response: ...', directly in line with the original example format.\n",
      "2025/11/10 11:46:47 INFO dspy.evaluate.evaluate: Average Metric: 1.7198387587495418 / 3 (57.3%)\n",
      "2025/11/10 11:46:47 INFO dspy.teleprompt.gepa.gepa: Iteration 6: New subsample score 1.7198387587495418 is not better than old score 2.3411449511900493, skipping\n",
      "GEPA Optimization:  63%|██████▎   | 57/90 [04:34<03:07,  5.70s/rollouts]2025/11/10 11:46:47 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Selected program 0 score: 0.793904358441594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.18 / 3 (72.6%): 100%|██████████| 3/3 [00:12<00:00,  4.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 11:47:00 INFO dspy.evaluate.evaluate: Average Metric: 2.1787418434572983 / 3 (72.6%)\n",
      "2025/11/10 11:47:00 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Exception during reflection/proposal: No valid predictions found for any module.\n",
      "2025/11/10 11:47:00 INFO dspy.teleprompt.gepa.gepa: Traceback (most recent call last):\n",
      "  File \"/home/siyanli/miniconda3/envs/omni/lib/python3.10/site-packages/gepa/proposer/reflective_mutation/reflective_mutation.py\", line 119, in propose\n",
      "    reflective_dataset = self.adapter.make_reflective_dataset(curr_prog, eval_curr, predictor_names_to_update)\n",
      "  File \"/home/siyanli/miniconda3/envs/omni/lib/python3.10/site-packages/dspy/teleprompt/gepa/gepa_utils.py\", line 288, in make_reflective_dataset\n",
      "    raise Exception(\"No valid predictions found for any module.\")\n",
      "Exception: No valid predictions found for any module.\n",
      "\n",
      "2025/11/10 11:47:00 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Reflective mutation did not propose a new candidate\n",
      "GEPA Optimization:  67%|██████▋   | 60/90 [04:47<02:43,  5.45s/rollouts]2025/11/10 11:47:00 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Selected program 0 score: 0.793904358441594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.17 / 3 (72.2%): 100%|██████████| 3/3 [00:15<00:00,  5.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 11:47:15 INFO dspy.evaluate.evaluate: Average Metric: 2.167184635780397 / 3 (72.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 11:47:33 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Proposed new text for proposer.predict: You are given a task to generate new user queries and corresponding assistant responses based on a set of provided example pairs. Each example pair includes a \"User Query\" and an \"Assistant Response\". \n",
      "\n",
      "Your goal is to create a wide variety of new, original instances that are sufficiently similar in structure, formality, and domain to the provided examples, while strictly adhering to a set of hard requirements:\n",
      "\n",
      "**Input Format:**\n",
      "- The input to the task consists of:\n",
      "  1. **examples**: A JSON-encoded list of existing (User Query, Assistant Response) pairs.\n",
      "  2. **data_summary**: (May be None or a textual summary of previous data.)\n",
      "  3. **requirement**: A textual specification of what must (or must not) be present in the User Query (e.g., \"User queries must contain personally identifiable information, such as names, addresses, nationalities, company names, and other named entities that would result in identifying the user.\").\n",
      "  \n",
      "**Task Description:**\n",
      "- Carefully analyze the **examples** to infer the domain, style, and complexity of expected user queries and assistant responses. Pay attention to patterns, types of PII, and the professional or technical jargon used in the examples.\n",
      "- Observe the strict requirement statements and ensure that ALL generated user queries comply fully (e.g., always include PII if required, or exclude PII if forbidden). Requirements may reference types of personal data, company names, technical entities, or other identifying details.\n",
      "- Avoid direct duplication of existing examples, whether in structure, specific scenario, or surface text. Your goal is to provide novel and diverse instances that remain close in purpose and form.\n",
      "- Outputs must cover the same general scenario types, use the same formality and tone, and be relevant to the inferred use case (such as professional email drafting, translation with PII, technical report writing, etc.).\n",
      "- If **Assistant Responses** are expected as part of the output (as inferred from examples), generate high-quality, context-appropriate replies that match the domain, depth, and politeness of the original responses.\n",
      "\n",
      "**Generation Strategy:**\n",
      "- Consider the strategies reflected in strong example generations: create realistic, plausible scenarios using varied but similar PII (names, places, entities), adapt linguistic variety, and ensure your outputs follow the plausible workflow (e.g., professional correspondence or technical request).\n",
      "- Balance diversity and similarity: Generations should be sufficiently distinct from provided examples but not so different that they lose relevance or deviate from the intended task.\n",
      "- If provided, use placeholders or realistic invented details for PII as appropriate (e.g., \"Dr. Maria Rossi, 12 Via Roma, Milan\").\n",
      "\n",
      "**Evaluation Considerations:**\n",
      "- Diversity is important, but do not stray too far from the examples: generations should have a moderate to high semantic similarity with the gold examples, neither duplicating them nor diverging into unrelated domains.\n",
      "- Adherence to the requirement is a hard constraint and must always be respected, even if it reduces diversity.\n",
      "- Ensure your generated examples retain the domain context (e.g., professional communication, technical support, translation with context) and contain or exclude PII as specified in the requirement.\n",
      "\n",
      "**You should:**\n",
      "- Read and interpret the provided examples and requirement.\n",
      "- Generate multiple novel (User Query, Assistant Response) pairs that strictly adhere to all criteria.\n",
      "- Ensure your responses are detailed, contextually appropriate, and reflect the inferred domain best practices.\n",
      "\n",
      "**DO NOT**:\n",
      "- Copy, paraphrase, or closely mimic any existing example from the input.\n",
      "- Generate queries that violate the hard requirement (e.g., omitting or including PII incorrectly).\n",
      "- Use unrealistic or implausible details or drift from the original domain/context.\n",
      "\n",
      "Your output should be a list of new (User Query, Assistant Response) pairs, formatted as in the examples, each complying exactly with the stated requirements and demonstrating a clear understanding of both the input examples and the task domain.\n",
      "2025/11/10 11:48:28 INFO dspy.evaluate.evaluate: Average Metric: 2.0378262791477812 / 3 (67.9%)\n",
      "2025/11/10 11:48:28 INFO dspy.teleprompt.gepa.gepa: Iteration 8: New subsample score 2.0378262791477812 is not better than old score 2.167184635780397, skipping\n",
      "GEPA Optimization:  73%|███████▎  | 66/90 [06:16<03:27,  8.63s/rollouts]2025/11/10 11:48:28 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Selected program 0 score: 0.793904358441594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.08 / 3 (69.2%): 100%|██████████| 3/3 [00:21<00:00,  7.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 11:48:50 INFO dspy.evaluate.evaluate: Average Metric: 2.0751110720935273 / 3 (69.2%)\n",
      "2025/11/10 11:48:50 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Exception during reflection/proposal: No valid predictions found for any module.\n",
      "2025/11/10 11:48:50 INFO dspy.teleprompt.gepa.gepa: Traceback (most recent call last):\n",
      "  File \"/home/siyanli/miniconda3/envs/omni/lib/python3.10/site-packages/gepa/proposer/reflective_mutation/reflective_mutation.py\", line 119, in propose\n",
      "    reflective_dataset = self.adapter.make_reflective_dataset(curr_prog, eval_curr, predictor_names_to_update)\n",
      "  File \"/home/siyanli/miniconda3/envs/omni/lib/python3.10/site-packages/dspy/teleprompt/gepa/gepa_utils.py\", line 288, in make_reflective_dataset\n",
      "    raise Exception(\"No valid predictions found for any module.\")\n",
      "Exception: No valid predictions found for any module.\n",
      "\n",
      "2025/11/10 11:48:50 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Reflective mutation did not propose a new candidate\n",
      "GEPA Optimization:  77%|███████▋  | 69/90 [06:37<02:55,  8.34s/rollouts]2025/11/10 11:48:50 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Selected program 0 score: 0.793904358441594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.05 / 3 (68.2%): 100%|██████████| 3/3 [00:15<00:00,  5.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 11:49:06 INFO dspy.evaluate.evaluate: Average Metric: 2.0472063027997365 / 3 (68.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 11:49:40 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Proposed new text for proposer.predict: You are given a task to generate new user query and assistant response pairs (called \"instances\") using a set of in-context examples and requirements. The goal is to create additional instances that match the thematic, stylistic, and content-related patterns found in the examples while satisfying explicit constraints described in the requirements.\n",
      "\n",
      "Input Format:\n",
      "- You receive inputs containing:\n",
      "  - **examples**: A list of existing user query and assistant response pairs. Each user query involves a user-specific request that includes identifiable information such as names, company names, addresses, nationalities, or other named entities. The assistant response addresses the user query in a polite, formal, and informative manner (typically as professional correspondence, information requests, technical or process explanations, translations, or interactive tests).\n",
      "  - **data_summary**: Either a brief summary or \"None\", indicating which specific examples or patterns should be avoided for duplication.\n",
      "  - **requirement**: An explicit constraint or series of constraints to strictly adhere to (e.g., \"User queries must contain personally identifiable information, such as names, addresses, nationalities, company names, and other named entities that would result in identifying the user.\").\n",
      "\n",
      "Detailed Task Description and Domain-Specific Notes:\n",
      "- The core aim is to generate new instance pairs that are *sufficiently similar* to the given examples to maintain topical, structural, and domain coherence, but not so similar that they are near-duplicates of the example or previous generated instances.\n",
      "- The domain of queries is generally professional or academic, including formal communication (e.g., emails to HR, embassies, universities), company documentation (e.g., website \"About us\" or \"Mission\"), translation requests, professional or academic introductions, explanations of technical issues, or MCQ-like Q&A for test preparation.\n",
      "- For each new user query:\n",
      "  - *You must* invent a scenario involving a realistic, but not previously used, combination of named entities (e.g., different names, companies, organizations, locations, email addresses, nationalities, etc.).\n",
      "  - Each user query should be unique in surface form and specifics but clearly fit the category/style of the examples given (formal requests, technical reporting, professional/academic introductions, business writing, etc.).\n",
      "  - All user queries must contain meaningful, substantive personally identifiable information (PII) relating to the user, as per the requirement.\n",
      "  - Avoid duplicating queries or situations already summarized in the **data_summary** or previously generated in this session.\n",
      "- For each assistant response:\n",
      "  - The response must directly address the user query, maintaining the level of formality, detail, and professionalism observed in the examples.\n",
      "  - Responses should follow appropriate formats (e.g., letter/email templates, step-by-step guidance, concise technical explanation, translation per request, MCQ questions if the context warrants).\n",
      "  - The response should introduce relevant content not found in the examples but justified given the context of the user query (e.g., procedures, contact details placeholders, process suggestions, explanations, etc.).\n",
      "- Generation strategy:\n",
      "  - Abstract the underlying communicative function and information content of the examples, then re-apply it to a different realistic scenario, ensuring both variation and domain fidelity.\n",
      "  - Ensure generated examples vary in named entities, scenarios, and document types, and avoid overfitting to just one narrow form present in the examples.\n",
      "  - Explicitly balance *similarity* (to be clearly related/relevant) with *diversity* (to avoid duplication and surpass minimum similarity thresholds indicated in feedback).\n",
      "  - If translation or technical issues are present in the examples, select new phrases or sentences to translate or diagnose, possibly in different languages, contexts, or objectives.\n",
      "\n",
      "Instructions for Generation:\n",
      "1. Read and internalize the patterns, content types, and tone of the examples.\n",
      "2. Carefully review the **data_summary** to ensure no duplication or near-duplication of summarized examples.\n",
      "3. Pay close attention to the **requirement**. If it says all queries must include PII, do not generate generic or anonymous queries.\n",
      "4. Generate several (e.g., 4-5) new user query and assistant response pairs:\n",
      "   - Each user query must pose a realistic, contextually appropriate request (e.g., an email to a specific person at an organization, a request for technical help at a named location, a translation task about a specific individual or address, a professional introduction with named degrees/affiliations, etc.).\n",
      "   - Each assistant response should be crafted to fully answer or address the request, in a matching professional format, tone, and style as the examples.\n",
      "5. Double-check that your outputs maximize diversity, avoid content repetition, and are clearly tied to the original in-context example topics and communicative intent.\n",
      "\n",
      "Remember: Your outputs will be evaluated both for sufficient similarity to the in-context style and content AND for their diversity (variation in topic, entities, and surface form).\n",
      "\n",
      "Summary: Synthesize new, diverse, and realistic user query/assistant response pairs that match provided example communication tasks (with strong PII and professional context), without repeating or copying any in-context or summarized instances, and while closely adhering to the genre, tone, and structure exemplified in the input.\n",
      "2025/11/10 11:50:28 INFO dspy.evaluate.evaluate: Average Metric: 2.7895950882811786 / 3 (93.0%)\n",
      "2025/11/10 11:50:28 INFO dspy.teleprompt.gepa.gepa: Iteration 10: New subsample score 2.7895950882811786 is better than old score 2.0472063027997365. Continue to full eval and add to candidate pool.\n",
      "2025/11/10 11:51:25 INFO dspy.evaluate.evaluate: Average Metric: 10.984014788005258 / 15 (73.2%)\n",
      "2025/11/10 11:51:25 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Full valset score for new program: 0.7322676525336839\n",
      "2025/11/10 11:51:25 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Full train_val score for new program: 0.7322676525336839\n",
      "2025/11/10 11:51:25 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Individual valset scores for new program: [1.0960138986814436, 0.6071794588255083, 1.1630871658064965, 0.6720550094910881, 1.1862634297386765, 0.6200400090584206, 0.6333005609471472, 0.5946664655345055, 0.5545552720851971, 0.5334599007984606, 0.5482039432199113, 0.5585160747864601, 0.5384943605172466, 0.5577487208450334, 1.120430517669662]\n",
      "2025/11/10 11:51:25 INFO dspy.teleprompt.gepa.gepa: Iteration 10: New valset pareto front scores: [1.2529988839560784, 0.6881640239849559, 1.2552401345433657, 0.691297050137833, 1.2567544480729285, 0.6900300232878139, 0.6333005609471472, 0.6777863360532537, 0.7026158997982547, 0.6756353703730471, 0.6872122998206088, 0.6673142319671626, 0.6696795287806736, 0.6855688274761842, 1.120430517669662]\n",
      "2025/11/10 11:51:25 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Full valset pareto front score: 0.8236018757912645\n",
      "2025/11/10 11:51:25 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Updated valset pareto front programs: [{0}, {0}, {0}, {0}, {0}, {0}, {2}, {0}, {0}, {0}, {0}, {0}, {0}, {0}, {2}]\n",
      "2025/11/10 11:51:25 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Best valset aggregate score so far: 0.793904358441594\n",
      "2025/11/10 11:51:25 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Best program as per aggregate score on train_val: 0\n",
      "2025/11/10 11:51:25 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Best program as per aggregate score on valset: 0\n",
      "2025/11/10 11:51:25 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Best score on valset: 0.793904358441594\n",
      "2025/11/10 11:51:25 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Best score on train_val: 0.793904358441594\n",
      "2025/11/10 11:51:25 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Linear pareto front program index: 0\n",
      "2025/11/10 11:51:25 INFO dspy.teleprompt.gepa.gepa: Iteration 10: New program candidate index: 2\n",
      "GEPA Optimization:  77%|███████▋  | 69/90 [09:12<02:48,  8.01s/rollouts]\n"
     ]
    }
   ],
   "source": [
    "from dspy import GEPA\n",
    "\n",
    "gepa = GEPA(metric=gepa_metric, track_stats=True, \n",
    "            reflection_lm=dspy.LM(model='gpt-4.1', temperature=1.0, max_tokens=32000),\n",
    "            track_best_outputs=True, max_full_evals=2)\n",
    "new_prog = gepa.compile(task_gen, trainset=train_set[:30], valset=dev_set[:15])\n",
    "pareto_frontier = new_prog.detailed_results.val_aggregate_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45c2c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = dspy.SIMBA(metric=metric, max_steps=3)\n",
    "# optimized_program = optimizer.compile(task_gen, trainset=train_set)\n",
    "\n",
    "# # Save optimize program for future use\n",
    "# optimized_program.save(f\"optimized.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18a7aa57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_prog.generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db21674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json.dump(optimized_program.generated_data, open(\"gen_data.json\", \"w+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9777402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
